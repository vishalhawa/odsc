{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'2.1.0'"
      ],
      "text/latex": [
       "'2.1.0'"
      ],
      "text/markdown": [
       "'2.1.0'"
      ],
      "text/plain": [
       "[1] \"2.1.0\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading objects:\n",
      "  df_paths\n",
      "  train_paths\n",
      "  test_paths\n"
     ]
    }
   ],
   "source": [
    "library(magrittr)\n",
    "library(dplyr)\n",
    "library(glue)\n",
    "library(data.table)\n",
    "library(ggplot2)\n",
    "library(tfdatasets)\n",
    "library(tensorflow)\n",
    "library(keras)\n",
    "tf$version$VERSION\n",
    "## load data Channel Dataset-----------------------------------------------------\n",
    "load(file = 'df_paths.rdata',verbose = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$embedding_V1\n",
       "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='V1', vocabulary_list=('channel_0', 'channel_1', 'channel_2', 'channel_3', 'channel_4', 'channel_5', 'channel_6', 'channel_7', 'channel_8'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
       "\n",
       "$embedding_V2\n",
       "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='V2', vocabulary_list=('channel_0', 'channel_1', 'channel_2', 'channel_3', 'channel_4', 'channel_5', 'channel_6', 'channel_7', 'channel_8'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
       "\n",
       "$embedding_V3\n",
       "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='V3', vocabulary_list=('channel_0', 'channel_1', 'channel_2', 'channel_3', 'channel_4', 'channel_5', 'channel_6', 'channel_7', 'channel_8'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
       "\n",
       "$embedding_V4\n",
       "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='V4', vocabulary_list=('channel_0', 'channel_1', 'channel_2', 'channel_3', 'channel_4', 'channel_5', 'channel_6', 'channel_7', 'channel_8'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
       "\n",
       "$embedding_V5\n",
       "EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='V5', vocabulary_list=('channel_0', 'channel_1', 'channel_2', 'channel_3', 'channel_4', 'channel_5', 'channel_6', 'channel_7', 'channel_8'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft_spec_target <- df_paths %>%\n",
    "      select(-customer_id,-path_no,-path) %>% \n",
    "      feature_spec(target ~ .) %>%\n",
    "      step_categorical_column_with_vocabulary_list(starts_with(\"V\"),vocabulary_list = list('channel_0', 'channel_1', 'channel_2', 'channel_3', 'channel_4', 'channel_5', 'channel_6', 'channel_7', 'channel_8')) %>%\n",
    "      step_embedding_column(starts_with(\"V\"), dimension = function(vocab_size) as.integer(sqrt(vocab_size) + 1)   ## dim=4\n",
    "      ) %>%\n",
    "  fit()\n",
    "\n",
    "ft_spec_target$dense_features() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "cat('Build model...\\n')\n",
    " n_lstm = 7\n",
    "batch_size = 32\n",
    "\n",
    "rnn_in <- layer_input_from_dataset(df_paths %>% select(-target)) \n",
    "\n",
    "rnn_out <- \n",
    "  rnn_in %>%\n",
    "  layer_dense_features(ft_spec_target$dense_features()) %>%\n",
    "  layer_reshape(target_shape= list(5,4))  %>%\n",
    "  bidirectional( layer_lstm(units = n_lstm, dropout = 0.2, recurrent_dropout = 0.2) ) %>%  # bidirectional not gain\n",
    "  layer_dense(units = 1, activation = 'sigmoid')\n",
    "\n",
    "rnn <- keras_model(rnn_in, rnn_out)\n",
    "\n",
    "rnn %>% \n",
    "  compile(\n",
    "    loss = \"binary_crossentropy\", \n",
    "    optimizer = \"adam\",\n",
    "    metrics = \"accuracy\"\n",
    "  )\n",
    "\n",
    "rnn %>% fit(x = df_paths %>% select(-target), y = df_paths$target, verbose=2,\n",
    "            validation_split = 0.2, epoch=20 ,batch_size=batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in cbind(df_paths, rnn_pred = predict(rnn, df_paths)): object 'df_paths' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in cbind(df_paths, rnn_pred = predict(rnn, df_paths)): object 'df_paths' not found\nTraceback:\n",
      "1. cbind(df_paths, rnn_pred = predict(rnn, df_paths))"
     ]
    }
   ],
   "source": [
    "rnn_scored = cbind( df_paths , rnn_pred = predict(rnn, df_paths) ) #%$% table(target,rnn_pred.V1)\n",
    "rnn_scored[customer_id=='id1000']\n",
    "\n",
    "## alter a value \n",
    "\n",
    "df_altered1 = df_paths[customer_id=='id1000', V4 := 'channel_5'][customer_id=='id1000'] \n",
    "df_altered1\n",
    "predict(rnn, df_altered1 )  ## Change in pred\n",
    "\n",
    "df_altered2 = df_paths[customer_id=='id1000', V4 := 'channel_0'][customer_id=='id1000'] \n",
    "predict(rnn, df_altered2 )  ## Change in pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
